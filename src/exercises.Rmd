---
title: "Software Übungen"
author: "Elliot Beck"
output: rmarkdown::github_document
knit: (function(inputFile, encoding) {
    rmarkdown::render(inputFile, encoding = encoding, output_dir = "../solutions/")
  })
---

```{r setup, include=FALSE}
# Get parent directory and set it as root.dir
current_dir <- dirname(getwd())
knitr::opts_knit$set(root.dir = current_dir)
```

## Aufgabe 1 

Aufgabe 13.3.6 im Buch von Ross (vom letzten Semester). Falls Sie das Buch nicht haben, hier ist eine "Kopie" der Aufgabe im Originalton:

The following data categorize a random selection of professors of a certain university according to their teaching performance (as measured by the students in their classes) in the most recent semester and the number of courses they were teaching at the time.

```{r}
# Erstellen des Datensatzes
ross_13_3_6 <- matrix(c(12, 10, 4, 32, 40, 38, 7, 12, 25),
    nrow = 3, byrow = TRUE,
    dimnames = list(c("Above", "Average", "Below"), c("1", "2", "3+"))
)
ross_13_3_6
```

Test, at the 5 percent level, the hypothesis that a professor's teaching performance is independent of the number of courses she or he is teaching.

```{r}
# Durchführung des Chi-Quadrat-Tests
chisq_test <- chisq.test(ross_13_3_6)
chisq_test
```

Da der p-Wert kleiner ist als 1%, können wir die Null-Hypothese verwerfen, dass die Evaluation unabhängig von der Anzahl der Kurse ist.

```{r}
round(chisq.test(ross_13_3_6)$expected, 1)
```

Ein Vergleich der beobachteten Tabelle mit der erwarteten Tabelle
zeigt, dass Professoren mit einem Kurs besser als erwartet (unter der
Null) abschneiden
während Professoren mit drei oder mehr Kursen schlechter als
erwartet (unter der Null) abschneiden. Damit gibt es einen negativen
Zusammenhang zwischen Evaluation und Anzahl der Kurse: wer mehr Kurse
unterrichted, wird im Durchschnit schlechter evaluiert.

## Aufgabe 2 

Der Datensatz "Medikament" enthält die Blutdrücke von n = 80 Patienten vor und nach der Behandlung mit einem Mittel, das hohen Blutdruck senken soll.

```{r}
# Einlesen der Daten für Aufgabe 2
medikament <- read.csv("data/medikament.csv")
head(medikament)
```

### a) Finden Sie ein 95% Konfidenz-Intervall für die durchschnittliche Blutdruck-Senkung. Erscheint das Medikament somit wirksam?

```{r}
# Berechnung des Konfidenz-Intervalls
senkung <- medikament$before - medikament$after
ci <- t.test(senkung)$conf.int
ci
```
Da dieses Konfidenz-Intervall die Null nicht enthält, ist es plausibel, dass das Medikament im Durchschnitt den Blutdruck senkt.

### b) Berechnen Sie die Stichproben-Korrelation zwischen "before" und "after".

```{r}
# Berechnung der Korrelation
cor(medikament$before, medikament$after)
```

### c) Wiederholen Sie anhand dieser Daten das Rechenbeispiel von Seite 28 der Folien 1

```{r}
# Direkte Berechnung von s_D
sd(senkung)

# Indirekte Berechnung von s_D
sqrt(var(medikament$before) + var(medikament$after) - 2 *
    cor(medikament$before, medikament$after) * sd(medikament$before) * sd(medikament$after))
```

### d) Erscheint das Medikament wirksamer als das Placebo?
Der Trick ist hier wie folgt. Zuerst berechnen wir die paarweise
Differenzen, einmal für das Medikament ($n_1=80$) und dann noch einmal für
das Placebo ($n_2 = 60$). Dann wenden wir das Konfidenz-Intervall für zwei
unabhängige Stichproben auf die zwei Differenz-Stichproben an

```{r}
# Einlesen der Placebodaten
placebo <- read.csv("data/placebo.csv")

# Berechnung der Konfidenz-Intervalle für die Differenzen
senkung_placebo <- placebo$before - placebo$after
t.test(senkung, senkung_placebo)$conf.int
```
Da dieses Konfidenz-Intervall die Null enthält, ist es plausibel,
dass das Medikament nicht besser ist als das Placebo.

## Aufgabe 3 

Der Datensatz enthält Aktienüberschussrenditen in Prozent für drei Aktien 
(Coca Cola, General Electrics und Sun Microsystems) sowie für den S&P 500 Aktien-Index von 
06/1992 bis 04/2002.

```{r}
# Einlesen der Daten für Aufgabe 3
aktien <- read.csv("data/aktien.csv")
head(aktien)
```

### a) Schätze die Parameter $\alpha$ und $\beta$ des CAPM.

```{r}
# CAPM-Modell
fit <- lm(sun.ex ~ sp500.ex, data = aktien)
summary(fit)
```
Wir erhalten die Schätzung $\hat{\alpha} = 1.6060$ und $\hat{\beta} = 1.8990$.

### b) Welches sind die drei einflussreichsten Beobachtungen laut der Cook's Distance?

```{r}
# Berechnung der Cook's Distance
plot(fit, main = "Cook's Distance", which = 4)
plot(cooks.distance(fit), type = "b", pch = 18, col = "red")
N <- nrow(aktien)
k <- 2
cutoff <- 4 / (N - k - 1)
abline(h = cutoff, lty = 2)
```

Es sind die Beobachtungen 94, 105 und 114. Allerdings hat keine
dieser Beobachtungen eine Cook's Distance, die als
"aussergewöhnlich" in Relation zur Grundgesamtheit beurteilt werden
kann.
Bemerkung: Es ist hier nicht hilfreich, sich univariate Boxplots
anzuschauen. Datenpunkte, die univariate Ausreisser sind (z.B. in der
Stichprobe der Sun-Daten) müssen keine Ausreisser in der bivariaten
Beziehung S&P--Sun mehr sein und umgekehrt!

### c) Kann die Aktie als 'defensiv' oder 'aggressiv' beurteilt werden?

```{r}
# Konfidenz-Intervall für Beta
confint(fit)["sp500.ex", ]
```
Da dieses KI die 1 nicht enthält, können wir die Aktie als "aggressiv" in Relation zum
Index beurteilen.

### d) Gibt es Anzeichen dafür, dass das CAPM verletzt ist?
Wir testen $H_0: \alpha = 0$ gegen $H_A: \alpha \neq 0$.

```{r}
# Hypothesentest für Alpha
summary(fit)$coefficients["(Intercept)", ]
```
Der zugehörige $p$-Wert (direkt von R berechnet für uns)
ist 0.159. Daher gibt es kein
Anzeichen für eine Verletzung des CAPM. Wir kommen zum gleichen
Ergebnis wenn wir ein 95% Konfidenz-Intervall für $\alpha$ in der
folgenden Weise
berechnen: $1.606 \pm 1.96 \times 1.133 = [-0.62, 3.83]$. Da dieses
Intervall die 0 enthält, ist es `plausibel', dass $\alpha = 0$
und somit können wir $H_0$ nicht verwerfen.

**Bemerkung**: ein Test für die Differenz der beiden Mittelwerte 
(Aktivum und Markt) ist hier nicht angebracht! Wenn ein Aktivum ein $\beta < 1$ hat, dann kann
$\alpha > 0$ sein, obwohl der Erwartungswert des Aktivums kleiner
ist als der des Marktes.

### e) Vorhersage der Überschussrendite bei einer neuen Monatsrisikoprämie von 3%

```{r}
# Vorhersage
new_data <- data.frame(sp500.ex = 3)
predict(fit, newdata = new_data)
```
Die Vorhersage ist 7.31. Allerdings ist
diese Vorhersage nicht sehr zuverlässig, da $R^2 = 0.29$. D.h. die
Risiko-Prämie des Indexes erklärt nur 29% der Variation der
Risiko-Prämie von Sun Microsystems.

### f) 95% Konfidenz-Intervall für die erwartete Überschussrendite

```{r}
# Konfidenz-Intervall
predict(fit, newdata = new_data, interval = "confidence")
```

## Aufgabe 4 

Der Datensatz enthält die Leidenszeit des Bööggs ("time") und die Anzahl der Sommertage ("days") für die Jahre 1965 bis 2018.

```{r}
# Einlesen der Daten für Aufgabe 4
boegg <- read.csv("data/boegg.csv")
head(boegg)
```

### a) Erstellen Sie ein Streuungs-Diagramm und beurteilen Sie die Beziehung.

```{r}
# Streudiagramm
plot(
    boegg$time, boegg$days,
    xlab = "Zeit", ylab = "Sommertage", main = "Streuungsdiagramm von Bööggs Leidenszeit"
)
```

### b) Wie lautet das geschätzte Modell?

```{r}
# Lineares Modell
fit_boegg <- lm(days ~ time, data = boegg)
summary(fit_boegg)
```
Die Beziehung ist sehr schwach, da weniger als 0.01% der beobachteten Variation in days durch time erklärt wird.

### c) Evidenz für die Behauptung des Volksmunds

```{r}
# Hypothesentest
summary(fit_boegg)$coefficients["time", ]
```
Der (einseitige) $p$-Wert ist 0.96/2 = 0.48 (da die Test-Statistik negativ ist). Daher haben wir
keine Evidenz für die Behauptung des Volksmunds.

### d) Vorhersage der Sommertage im Jahr 2019

```{r}
# Vorhersage für 2019
new_data <- data.frame(time = 17.73)
predict(fit_boegg, newdata = new_data, interval = "prediction", level = 0.90)
```
Die Vorhersage ist $\hat y_{neu} = 39.0$. Das Vorhersage-Intervall ist $[17.3, 60.7]$.
Es wäre aber keine gute Idee: sowohl vom
Streuungs-Diagramm mit geschätzter Gerade als auch vom
Normal-Quantil-Plot können wir sehen, dass die Residuen rechtsschief
sind.

### e) Änderung der Ergebnisse ohne einflussreiche Beobachtungen

```{r}
# Entfernung der einflussreichen Beobachtungen
cooksd_boegg <- cooks.distance(fit_boegg)
influential_boegg <- which(cooksd_boegg > (4 / (nrow(boegg) - 2 - 1)))
boegg_no_infl <- boegg[-influential_boegg, ]

# Neues Modell ohne einflussreiche Beobachtungen
fit_boegg_no_infl <- lm(days ~ time, data = boegg_no_infl)
summary(fit_boegg_no_infl)
predict(fit_boegg_no_infl, data.frame(year = 2019, days = 10, time = 17.73),
    interval = "prediction", level = 0.90
)
```
Wenn diese Beobachtung entfernt wird, ändert sich so gut wie nichts.

## Aufgabe 5
Die Datei "cocaine.csv" enthält 56 Observationen von Variablen welche im Zusammenhang mit dem
Verkauf von Kokain in Nordosten von Kalifornieren zwischen 1984-1991 stehen. 

Die Variablen sind:\
- price: Preis pro Gramm in Dollar\
- quant: Menge in Gram für eine Transaktion\
- qual: Qualität des Kokains in Reinheitsgrad in Prozent\
- trend: Eine Zeitvariable mit 1984 = 1, 1985 = 2, ..., 1991 = 8\

Betrachten wir folgendes Regressionsmodell:\
$price = \beta_1 + \beta_2 \cdot quant + \beta_3 \cdot qual + \beta_4 \cdot trend + \varepsilon$

```{r} 
# Einlesen der Daten für Aufgabe 5
cocaine <- read.csv("data/cocaine.csv")
```

### a) Welche Vorzeichen erwarten Sie für die Koeffizienten $\beta_2$, $\beta_3$ und $\beta_4$?
Negativ, Positiv, nicht klar.

### b) Schätzen Sie das Modell und interpretieren Sie die Koeffizienten. Sind die Vorzeichen wie erwartet?
```{r} 
fit_cocaine <- lm(price ~ quant + qual + trend, data = cocaine)
summary(fit_cocaine)
```

### c) Wie gross ist der Anteil der erklärten Variation von $price$ durch die Variation von $quant$, $qual$ und $trend$?
51%, siehe b).

### d) Es wird behauptet, dass das Risiko aufzufliegen mit der Verkaufssumme steigt. Die Verkäufer wären also bereit, tiefere Preise zu akzeptieren, wenn die Menge steigt. Setzten sie eine passende $H_0$ und $H_A$ auf und testen Sie die Hypothese.
Wir testen $H_0: \beta_2 = 0$ gegen $H_A: \beta_2 < 0$. 
Die zugehörige Test-Statistik ist $t = -5.892$ (siehe b) und der
zugehörige $p$-Wert ist $\approx 0$. (Da es sich um einen
einseitigen Test handelt, und die Test-Statistik negativ ist, müssen
wir den angegebenen $p$-Wert 2.85e-07 halbieren.) 
Damit ist die Vermutung bestätigt. 

### e) Testen sie die Hypothese, dass die Qualität des Kokains keinen Einfluss auf den Preis hat gegen die Alternative, dass die Qualität einen Einfluss auf den Preis hat.
Wir testen $H_0: \beta_3 = 0$ gegen $H_A: \beta_3 > 0$. Die
zugehörige Test-Statistik ist $t = 0.572$ (siehe b) und der zugehörige
(einseitige) $p$-Wert ist $0.57 /2 = 0.285$. Damit können wir $H_0$
nicht verwerfen und es ist plausibel (aber nicht bewiesen), dass die
Qualität keinen Einfluss auf den Preis hat.

### f) Was ist die durchschnittliche Änderung des Preises pro Gramm pro Jahr? Können sie erklären, warum sich der Preis in diese Richtung entwickelt?
Preissenkung von $2.35 pro Jahr. Eine mögliche Erklärung ist, dass mehr und
mehr Kokain auf den Markt kommt und der Preis daher sinkt.

### g) Kommentieren Sie die Gültigkeit der vorangegangenen Hypothesen-Tests. Benützen Sie hierzu, unter anderem, das verfeinerte Residuen-Diagramm anstelle des `normalen' Residuen-Diagramms.
Bei den Daten handelt es sich teilweise um eine Zeitreihe. (Es ist
keine Zeitreihe im "strikten Sinne", da es mehrere Beobachtungen pro
Jahr gibt. Solche Daten heissen *Panel-Daten*.) Also ist Vorsicht
geboten. Zudem erkennt man eine Fächer-Form im Residuen-Diagramm
(recht klar) und eine halbe Fächer-Form im verfeinerten
Residuen-Diagramm (etwas weniger klar). Die Inferenz ist also mit
Vorsicht zu geniessen. 

### h) Ein Verkäufer bietet 1993 ein Paket an mit $quant = 100$ und $qual = 60$. Berechnen Sie ein 90% Vorhersage-Intervall für den Preis, den er erzielen wird. Inwieweit vertrauen Sie diesem Intervall?
```{r} 
# option 1
predict(fit_cocaine, data.frame(price = 0, quant = 100, qual = 60, trend = 10), se = T)

# option 2
predict(fit_cocaine, data.frame(price = 0, quant = 100, qual = 60, trend = 10), interval = "prediction", level = 0.90)
```

Das Vorhersage-Intervall ist daher $[32.0, 104.5]$. Wir haben
weiterhin die Bedenken aus Teil g). Zusätzlich gibt das
Normal-Quantil-Diagramm einen (leichten) Hinweis auf das "Heavy
Tails" Muster. Also ist das Vorhersage-Intervall zusammengenommen
nicht sehr vertrauenswürdig. 


## Aufgabe 6
Eine junge Person arbeitet seit drei Jahren in ihrem Beruf. Sie fragt
sich, ob sie in ihrer Karriere weitermachen sollte oder ob sie einen
fortgeschrittenen Studienabschluss machen sollte, um danach in das
Berufsleben zurückzukehren. Der Datensatz "berufe.csv" enthält Daten von einer
Zufalls-Stichprobe von Arbeitern in der zugehörigen Industrie:\
- Gehalt (in 1'000 Euro)\
- Arbeitsjahre \
- Art des Studienabschlusses (0 für normal und 1 für fortgeschritten)

```{r}
# Einlesen der Daten für Aufgabe 6
berufe <- read.csv("data/berufe.csv")
```

### a) Erstellen Sie ein Streuungsdiagramm mit unterschiedlichen Farben für die beiden Abschlüsse. Welche `Botschaft' vermittelt Ihnen dieses Diagramm?
```{r}
plot(berufe$jahre, berufe$gehalt,
    col = berufe$abschluss + 1, xlab = "Jahre", ylab = "Salär", main =
        "Streuungsdiagram Gehalt vs Jahre"
)
legend("bottomright", legend = c("Normal", "Fortgeschritten"), col = 1:2, pch = 1)
```

Es suggeriert, was die formale
Analyse später bestätigen wird. Die Gerade für die Gruppe mit
dem fortgeschrittenen Abschluss hat nicht nur einen höheren
Abschnitt sondern auch eine grössere Steigung. Ausserdem enthält
die Gruppe mit dem normalen Abschluss einen klaren Ausreisser.

### b) Schätzen das Modell Gemeinsame Gerade für beide Gruppen (normaler und fortgeschrittener Abschluss) und interpretieren Sie das geschätzte Modell.
```{r}
fit_beruf <- lm(gehalt ~ jahre, data = berufe)
summary(fit_beruf)
```

$G$ = Gehalt, $J$ = Jahre und $A$ = Abschluss.\
Geschätzes Modell: $\hat G = 41.56 + 1.45 J$. Somit
ist die geschätzte durchschnittliche Gehaltserhöhung 1'450 pro Jahr.
Das geschätzte durchschnittliche Anfangsgehalt beträgt 41'5600.

### c) Sollten Sie zu dem Modell Gemeinsame Steigung übergehen? Falls ja, interpretieren Sie das geschätze Modell.
```{r}
fit_beruf_2 <- lm(gehalt ~ jahre + abschluss, data = berufe)
summary(fit_beruf_2)
```

Der $p$-Wert der zusätzlichen Variable $A$ ist ungefähr gleich
Null, also sollten wir zum Modell Gemeinsame Steigung
übergehen. Das geschätzte Modell ist $\hat G = 32.85 + 17.62 A +
1.60 J$.  Somit
ist die geschätzte gemeinsame durchschnittliche Gehaltserhöhung 1'600 pro Jahr.
Das geschätzte durchschnittliche Anfangsgehalt beträgt 32'850 in
der Gruppe mit dem normalen Abschluss und 32'850 + 17'620 = 50'470
in der Gruppe mit dem fortgeschrittenen Abschluss.

### d) Sollten Sie zu dem Modell Total Verschieden übergehen? Falls ja, interpretieren Sie das geschätzte Modell.
```{r}
fit_beruf_3 <- lm(gehalt ~ jahre + abschluss + jahre:abschluss, data = berufe)
summary(fit_beruf_3)
```

Der $p$-Wert der zusätzlichen Variable $(A \times J)$ ist ungefähr gleich
Null, also sollten wir zu "Total Verschieden"
übergehen. Das geschätzte Modell ist:

$$\hat{G} = 34.61 + 7.42 A + 1.48 J + 0.80 (A \times J)$$.

Somit ist die geschätzte durchschnittliche Gehaltserhöhung 1'480 pro
Jahr in der Gruppe mit dem normalen Abschluss und 1'480 + 800 = 2'280
in der Gruppe mit dem fortgeschrittenen Abschluss.
Das geschätzte durchschnittliche Anfangsgehalt beträgt 34'610 in
der Gruppe mit dem normalen Abschluss und 34'610 + 7'420 = 40'030
in der Gruppe mit dem fortgeschrittenen Abschluss.

### e) In dem Modell, das Ihnen am besten erscheint, suchen Sie nach (klaren) Ausreissern und entfernen Sie diese. Für den Rest der Aufgabe benützen Sie dann dieses Modell. Was ist der Prozentsatz der beobachteten Variation von Gehalt, der von diesem Modell erklärt wird.
```{r}
# Suchen nach Ausreissern (Cook's Distance, Obs. 67 sieht nach Ausreisser aus)
plot(fit_beruf_3, which = 4)
fit_beruf_4 <- lm(gehalt ~ jahre + abschluss + jahre:abschluss, data = berufe[-67, ])
summary(fit_beruf_4)
```
Datenpunkt Nr. 67 ist ein klarer Ausreisser. 
Das geschätze Modell nach dem
Entfernen diese Punktes ist dann: 

$$\hat{G} = 34.23 + 7.8 * A + 1.53 * J+ 0.76 * (A \times J)$$. 

Dieses Modell erklärt 88% der beobachteten Variation des Gehalts.

### f) Finden Sie ein 90% Konfidenz-Intervall für die Steigung von Arbeitsjahren in der Gruppe mit dem normalen Abschluss. Benützen Sie hierzu die standard OLS-Inferenz. Glauben Sie, dass Sie diesem Intervall vertrauen können?
```{r}
confint(fit_beruf_4, level = 0.9)["jahre", ]
plot(fit_beruf_4, which = 1)
plot(fit_beruf_4, which = 3)
```

Das 90% Konfidenz-Intervall ist $[1.41, 1.64]$. Jedoch zeigt das Residuen-Diagramm eine Fächer-Form
und, äquivalent, das verfeinerte Residuen-Diagramm eine halbe
Fächer-Form. Also sollten wir diesem Intervall nicht trauen.

### g) Falls Ihre Antwort in (f) nein war, finden Sie ein KI, dem Sie vertrauen können. Benützen Sie hierzu geeignete HC-Inferenz.
```{r}
# HC3 Inference
lmtest::coeftest(fit_beruf_4, vcov = sandwich::vcovHC(fit_beruf_4, type = "HC3"))["jahre", ]
```

Das 90% Konfidenz-Intervall basierend auf dem HC3 Standardfehler
ist gegeben als
$1.53 \pm 1.645 \times 0.080 = [1.40, 1.66]$, und diesem Intervall
können wir vertrauen. In der Regel (wie auch hier), jedoch nicht
immer, werden die Konfidenz-Intervalle für Steigungen im Falle der
Berücksichtigung von HC etwas länger.

### h) Nehmen wir an die Person ist momentan 27 Jahre alt und dass es zwei Jahre dauern würde, den fortgeschrittenen Abschluss zu erwerben. Sagen Sie ihr Gehalt im Alter von 30 Jahren und 45 Jahren vorher für jede der beiden folgenden Strategien (und ohne die Inflation in Betracht zu ziehen):

#### h1) Sie arbeitet in ihrer Industrie weiter.

#### h2) Sie erwirbt den fortgeschrittenen Abschluss und kehrt dann in ihre Industrie zurück, um dort weiterzuarbeiten.

(**Bemerkung**: nur Vohersagen, keine Vorhersage-Intervalle.)

Die Person ist 27 Jahre alt und hat momentan 3 Arbeitsjahre. Dies
ergibt die folgenden Arbeitsjahre für die betrachteten Alter und
Strategien. (Bemerkung: den fortgeschrittenen Abschluss zu erwerben
"kostet" die Person zwei Arbeitsjahre).

```{r echo = FALSE}
knitr::kable(
    data.frame(
        " " = c("Alter = 30", "Alter = 45"),
        "Strategie (g1)" = c(6, 21),
        "Strategie (g2)" = c(4, 19)
    ),
    col.names = c("", "Strategie (g1)", "Strategie (g2)"),
    align = c("l", "c", "c"),
    caption = " "
)
```

Wenn man diese Werte in das geschätzte Modell von e) einsetzt,
erhält man die folgenden Vorhersagen.

```{r echo = FALSE}
knitr::kable(
    data.frame(
        " " = c("Alter = 30", "Alter = 45"),
        "Strategie (g1)" = c(43.41, 51.19),
        "Strategie (g2)" = c(66.36, 85.54)
    ),
    col.names = c("", "Strategie (g1)", "Strategie (g2)"),
    align = c("l", "c", "c"),
    caption = " "
)
```

**Bemerkung**: Strenggenommen ist die standard OLS-Inferenz in b) und c) nicht
gültig, da die Annahme der konstanten Fehler-Standardabweichung
verletzt ist. Aber die $p$-Werte sind so extrem klein, dass sich die
Resultate nicht ändern würden wenn man eine allgemeinere
Inferenzmethode wählen würde, die diese Annahme nicht
benötigt. Sie können dies nachprüfen, indem Sie die Inferenz
stattdessen auf den HC3 Standardfehlern basieren.
Alternativ könnte man auch das Kriterium der
adjustierten $R^2$-Statistik wühlen und küme zu dem gleichen
Schluss: man muss schlussendlich zum Modell "Total Verschieden" übergehen.

## Aufgabe 7

Betrachten Sie Produktionsfunktionen der Art $Q = f(L,K)$, wobei $Q$
ein Mass für Output ist, $L$ Labor-Input ist und $K$ Kapital-Input
ist. Eine populäre funktionale Form ist die Cobb-Douglas-Gleichung:\
$\log Q_i = \beta_1 + \beta_2 \log L_i + \beta_3 \log K_i + u_i~. $\
Die Daten für diese AUfgabe sind in der Datei "production.csv" gespeichert.

```{r}
# Einlesen der Daten für Aufgabe 7
production <- read.csv("data/production.csv")
```

### a) Testen Sie die constant returns to scale Hypothese, d.h., $H_0: \beta_2 + \beta_3 = 1$\
```{r}
fit_production <- lm(log(Q) ~ log(L) + log(K), data = production)
fit_constant_returns <- lm(I(log(Q) - log(K)) ~ I(log(L) - log(K)), data = production)
summary(fit_production)
summary(fit_constant_returns)
```

Somit haben wir $SSR_0 = 0.2135^2 \times 31 = 1.413$ und $SSR_A =
0.2167^2 * 30 = 1.409$. Die Test-Statistik ist dann:\
$$F = \frac{(1.413 - 1.409)/1}{1.409 /30} = 0.0852$$
Der $p$-Wert ist damit $P(F_{1,30} \ge 0.0852) = 0.77$. Somit ist die
"constant returns to scale" Hypothese plausibel. Alternativ können
wir den $F$-Test auch "direkt" ausführen:

```{r}
car::linearHypothesis(fit_production, hypothesis.matrix = c(0, 1, 1), rhs = 1)
```

Die leichten Unterschiede hierbei sind auf die Rundungsfehler
zurückzuführen, wenn der Test "von Hand" ausgeführt wird.

### b) Man beobachtet $K = 20$ und $L = 25$. Finden Sie ein 95% Vorhersage-Intervall für $Q$ unter der Annahme, dass die constant returns to scale Hypothese gültig ist. Vertrauen Sie diesem Intervall? (Achtung: etwas trickreich...) Bemerkung: Gehen Sie von Homoskedastie hier aus.

```{r}
# Berechnung des Vorhersage-Intervalls "von Hand"
predicition <- predict(fit_constant_returns, data.frame(K = 20, L = 25, Q = 0), se = T)
quantile <- qt(0.975, 31)
lower_bound <- exp(predicition$fit - quantile * sqrt(predicition$se.fit^2 + predicition$residual.scale^2) + log(20))
upper_bound <- exp(predicition$fit + quantile * sqrt(predicition$se.fit^2 + predicition$residual.scale^2) + log(20))
print(paste0("[", lower_bound, ", ", upper_bound, "]"))
```

Das geschützte Modell unter $H_0$ gibt uns ein Vorhersage-Intervall
für $\log(Q) - \log(20)$. Um dieses in ein Vorhersage-Intervall für
$Q$ umzuwandeln, müssen wir auf jeden Endpunkt die Invers-Transformation
$f(a) = \exp(a + \log(20))$ anwenden. Das Ergebnis ist das Intervall
\mbox{[13.9, 35.9]}. Etwas trickreich, zugegebenermassen.

Schneller erhalten wir das Vorhersage-Intervall in der transformierten
Welt wie folgt:\

```{r}
exp(predict(fit_constant_returns, data.frame(K = 20, L = 25, Q = 0),
    interval = "prediction", level = 0.95
) + log(20))
```

Das Endergebnis ist (bis auf kleine Rundungsfehler) natürlich identisch.

Allerdings ist der Stichprobenumfang recht
klein mit $n = 30$ und das Normal-Quantil-Diagramm zeigt das "Heavy
Tails" Muster.
Man sollte dem Vorhersage-Intervall daher nicht
übermässig vertrauen.

Gefahrendiagramm:\

```{r}
plot(fit_constant_returns, which = 2)
```